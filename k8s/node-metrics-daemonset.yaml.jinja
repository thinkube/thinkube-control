---
apiVersion: v1
kind: Service
metadata:
  name: node-metrics
  namespace: {{ namespace }}
  labels:
    app: node-metrics
spec:
  selector:
    app: node-metrics
  ports:
    - name: http
      port: 9100
      targetPort: 9100
  type: ClusterIP
---
apiVersion: apps/v1
kind: DaemonSet
metadata:
  name: node-metrics
  namespace: {{ namespace }}
  labels:
    app: node-metrics
spec:
  selector:
    matchLabels:
      app: node-metrics
  template:
    metadata:
      labels:
        app: node-metrics
    spec:
      hostPID: true
      containers:
      - name: node-metrics
        image: python:3.11-slim
        command:
          - sh
          - -c
          - |
            apt-get update -qq && apt-get install -y -qq util-linux > /dev/null 2>&1
            python3 -u << 'PYTHON_EOF'
            from http.server import BaseHTTPRequestHandler, HTTPServer
            import json
            import subprocess

            class MetricsHandler(BaseHTTPRequestHandler):
                def do_GET(self):
                    if self.path == "/metrics":
                        try:
                            # Read /proc/meminfo
                            with open("/host/proc/meminfo", "r") as f:
                                meminfo = {}
                                for line in f:
                                    parts = line.split(":")
                                    if len(parts) == 2:
                                        key = parts[0].strip()
                                        value = parts[1].strip().split()[0]
                                        meminfo[key] = int(value) * 1024

                            # Read /proc/stat for CPU (read twice to calculate percentage)
                            import time
                            def read_cpu_times():
                                with open("/host/proc/stat", "r") as f:
                                    cpu_line = f.readline()
                                    cpu_times = [int(x) for x in cpu_line.split()[1:]]
                                    return sum(cpu_times), cpu_times[3]  # total, idle

                            total_1, idle_1 = read_cpu_times()
                            time.sleep(0.2)  # Brief delay to measure delta
                            total_2, idle_2 = read_cpu_times()

                            total_delta = total_2 - total_1
                            idle_delta = idle_2 - idle_1
                            cpu_percent = 100.0 * (1 - idle_delta / total_delta) if total_delta > 0 else 0.0

                            # Get GPU stats from nvidia-smi (run in host namespace using nsenter)
                            def safe_float(value, default=0):
                                try:
                                    v = value.strip()
                                    if v.lower() in ['[n/a]', 'n/a', '[not supported]', 'not supported']:
                                        return default
                                    return float(v)
                                except (ValueError, AttributeError):
                                    return default

                            try:
                                result = subprocess.run(
                                    ["nsenter", "-t", "1", "-m", "-u", "-n", "-i", "nvidia-smi", "--query-gpu=utilization.gpu,memory.used,memory.total,temperature.gpu,power.draw", "--format=csv,noheader,nounits"],
                                    capture_output=True, text=True, timeout=2
                                )
                                if result.returncode == 0:
                                    gpu_data = result.stdout.strip().split(",")
                                    gpu_util = safe_float(gpu_data[0])
                                    gpu_mem_used = safe_float(gpu_data[1])
                                    gpu_mem_total = safe_float(gpu_data[2])
                                    gpu_temp = safe_float(gpu_data[3])
                                    gpu_power = safe_float(gpu_data[4])
                                else:
                                    gpu_util = 0
                                    gpu_mem_used = 0
                                    gpu_mem_total = 0
                                    gpu_temp = 0
                                    gpu_power = 0
                            except Exception:
                                gpu_util = 0
                                gpu_mem_used = 0
                                gpu_mem_total = 0
                                gpu_temp = 0
                                gpu_power = 0

                            metrics = {
                                "memory_total_bytes": meminfo.get("MemTotal", 0),
                                "memory_free_bytes": meminfo.get("MemFree", 0),
                                "memory_available_bytes": meminfo.get("MemAvailable", 0),
                                "memory_used_bytes": meminfo.get("MemTotal", 0) - meminfo.get("MemAvailable", 0),
                                "memory_buffers_bytes": meminfo.get("Buffers", 0),
                                "memory_cached_bytes": meminfo.get("Cached", 0),
                                "cpu_percent": cpu_percent,
                                "gpu_utilization": gpu_util,
                                "gpu_memory_used_mb": gpu_mem_used,
                                "gpu_memory_total_mb": gpu_mem_total,
                                "gpu_temp": gpu_temp,
                                "gpu_power": gpu_power
                            }

                            self.send_response(200)
                            self.send_header("Content-type", "application/json")
                            self.end_headers()
                            self.wfile.write(json.dumps(metrics).encode())
                        except Exception as e:
                            self.send_response(500)
                            self.send_header("Content-type", "application/json")
                            self.end_headers()
                            self.wfile.write(json.dumps({"error": str(e)}).encode())
                    else:
                        self.send_response(404)
                        self.end_headers()

                def log_message(self, format, *args):
                    pass

            server = HTTPServer(("0.0.0.0", 9100), MetricsHandler)
            print("Node metrics server started on port 9100")
            server.serve_forever()
            PYTHON_EOF
        ports:
        - containerPort: 9100
          name: http
        volumeMounts:
        - name: proc
          mountPath: /host/proc
          readOnly: true
        resources:
          requests:
            memory: 64Mi
            cpu: 10m
          limits:
            memory: 256Mi
            cpu: 100m
        securityContext:
          privileged: true
          readOnlyRootFilesystem: false
      volumes:
      - name: proc
        hostPath:
          path: /proc
          type: Directory
      tolerations:
      - effect: NoSchedule
        operator: Exists
